# -*- coding: utf-8 -*-
"""train.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U49jew1FW3Y7RSGplKBVlIBw9wFc7N-x
"""

import time
import torch

# Sélection du dispositif (CPU ou GPU)
device = 'cpu'
if torch.cuda.is_available():
    device = 'cuda'

def epoch_time(start_time, end_time):
    """
    Calcule le temps écoulé entre deux moments en minutes et secondes.

    Args:
        start_time (float): Temps de début.
        end_time (float): Temps de fin.

    Returns:
        tuple: Temps écoulé en minutes et secondes.
    """
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs

def train(model, num_epochs, trainloader, testloader, criterion, optimizer, validation_phase=False):
    """
    Entraîne le modèle spécifié pour un certain nombre d'époques.

    Args:
        model (nn.Module): Le modèle PyTorch à entraîner.
        num_epochs (int): Le nombre d'époques d'entraînement.
        trainloader (DataLoader): DataLoader pour l'ensemble d'entraînement.
        testloader (DataLoader): DataLoader pour l'ensemble de test.
        criterion: La fonction de perte à utiliser pour calculer l'erreur.
        optimizer: L'optimiseur utilisé pour la mise à jour des poids du modèle.
        validation_phase (bool): Indique si la phase actuelle est la validation.

    Returns:
        tuple: Les moyennes des pertes d'entraînement et de test, ainsi que les précisions d'entraînement et de test.
    """
    train_avg_loss = []
    test_avg_loss = []
    test_accuracy = []
    train_accuracy = []

    for i in range(num_epochs):
        train_losses = []
        test_losses = []
        correct_train = 0
        total_train = 0

        for x, y in trainloader:
            start_time = time.monotonic()
            x, y = x.to(device), y.to(device)

            pred = model(x)
            loss = criterion(pred, y)
            train_losses.append(loss.detach())

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Calcul de la précision d'entraînement
            y_pred_train = pred.argmax(dim=-1)
            correct_train += (y_pred_train == y).sum().item()
            total_train += y.size(0)

        with torch.no_grad():
            correct_test = 0
            total_test = 0

            loader = testloader

            for x, y in loader:
                x, y = x.to(device), y.to(device)

                pred = model(x)
                loss = criterion(pred, y)
                test_losses.append(loss)

                y_pred_test = pred.argmax(dim=-1)
                correct_test += (y_pred_test == y).sum().item()
                total_test += y.size(0)

            # Calcul de la précision
            accuracy_train = correct_train / total_train
            accuracy_test = correct_test / total_test
            test_accuracy.append(accuracy_test)

        train_avg_loss.append(torch.mean(torch.tensor(train_losses)).detach())
        test_avg_loss.append(torch.mean(torch.tensor(test_losses)).detach())

        print("Epoch [{}/{}], Test Loss: {:.4f}, Test Accuracy: {:.2f}%, Train Loss: {:.4f}, Train Accuracy: {:.2f}%".format(
            i+1, num_epochs, test_avg_loss[-1], accuracy_test*100, train_avg_loss[-1], accuracy_train*100))

        end_time = time.monotonic()
        epoch_mins, epoch_secs = epoch_time(start_time, end_time)

        print(f'| Epoch Time: {epoch_mins}m {epoch_secs}s')

        train_accuracy.append(accuracy_train)

    # Sauvegarde du modèle à la fin de l'entraînement
    torch.save(model.state_dict(), 'model.pt')

    return train_avg_loss, test_avg_loss, test_accuracy, train_accuracy

